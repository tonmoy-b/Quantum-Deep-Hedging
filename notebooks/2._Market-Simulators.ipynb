{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97faed27-0a98-46f1-a4c0-e083d40a81ef",
   "metadata": {},
   "source": [
    "This notebook implements the market simulators for Deep Hedging. Two models are implemented and constrasted: (1) GBM and (2) Heston Market Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b25a3-f75c-4d2d-82b3-399dfa6712bc",
   "metadata": {},
   "source": [
    "First, the code structure is arranged here in accordance to OOP principles. This will allow easy development of testing and also that of transferring the code to external FASTApi apps. However, jupyter notebooks will be the research base for clear communication and noting of research/design decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb0f02-890f-46ff-9021-b972f30ec3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1278802-ca5f-49b3-9679-eb1fb4ad9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class MarketSimulator(nn.Module, ABC):\n",
    "    \"\"\"\n",
    "    Abstract Base Class for Market Simulators. \n",
    "    To fascilitate interfacing between different models interchangeably with the rest of the system\n",
    "    \n",
    "    Output Shape for simulation data: [Batch_Size, Time_Steps, Features]\n",
    "    \"\"\"\n",
    "    def __init__(self, dt, device):\n",
    "        super().__init__()\n",
    "        self.dt = dt\n",
    "        self.device = device\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, num_paths, num_steps, initial_prices):\n",
    "        \"\"\"\n",
    "        Generates the market paths.\n",
    "        \n",
    "        Args:\n",
    "            num_paths (int): Number of Monte Carlo simulations. This is the Batch Size of the model.\n",
    "            num_steps (int): Number of discrete time-steps (T).\n",
    "            initial_prices (Tensor): Starting prices S_0 [Batch, Assets].\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: The simulated market states.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87334b7d-e4c8-4796-8f3d-bf0ef9f75a49",
   "metadata": {},
   "source": [
    "The first model: Geometric Brownian Motion (GBM)\n",
    "\n",
    "This model is defined by the Stochastic Differential Equation: $$dS_t = \\mu S_t dt + \\sigma S_t dW_t$$\n",
    "\n",
    "Where, \n",
    "* $S_t$: Asset price at time $t$.\n",
    "* $\\mu$: Drift (constant trend of the asset).\n",
    "* $\\sigma$: Volatility (constant standard deviation of returns).\n",
    "* $dW_t$: A standard Brownian Motion (Wiener Process).\n",
    "\n",
    "This SDE is discretized as:  $S_{t+\\Delta t} = S_t (1 + \\mu \\Delta t + \\sigma \\sqrt{\\Delta t} Z)$\n",
    "\n",
    "The above was in price terms, instead of prices themselves log of prices maybe utilized\n",
    "\n",
    "Log-Price Space ($x_t = \\ln S_t$) \n",
    "\n",
    "For which, the GBM SDE can be subjected to It√¥'s Lemma:$$dx_t = \\left( \\mu - \\frac{1}{2}\\sigma^2 \\right) dt + \\sigma dW_t$$\n",
    "This SDE is discretized as: $x_{t+\\Delta t} = x_t + (\\mu - 0.5\\sigma^2)\\Delta t + \\sigma \\sqrt{\\Delta t} Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d351eed-ab28-4e3d-a981-677199a89a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pyt_gbm(S0, mu, sigma, T, dt, n_paths, use_log=True):\n",
    "    steps = int(T / dt)\n",
    "    n_paths = int(n_paths)\n",
    "    \n",
    "    # Generate noise by drawing from std-normal-distribution, hence with mean=0, var=1\n",
    "    Z = torch.randn(steps, n_paths) #[steps x paths matrix, so each column in a path]\n",
    "\n",
    "    # Paths generated in either price and log-price  \n",
    "    if use_log:\n",
    "        # Log-price: provides numerical stability with non-negative values due to log and also due to additive updates\n",
    "        drift = (mu - 0.5 * sigma**2) * dt\n",
    "        diffusion = sigma * torch.sqrt(torch.tensor(dt)) * Z\n",
    "        log_increments = drift + diffusion\n",
    "        \n",
    "        # cumulative sum of log-returns using cumsum\n",
    "        x = torch.log(torch.tensor(S0)) + torch.cumsum(log_increments, dim=0)\n",
    "        return torch.exp(x)\n",
    "    else:\n",
    "        # Price-space: disadvantaged relative to log-prices due to potential for negative values and also multiplicative updates\n",
    "        # S_{t+1} = S_t * (1 + mu*dt + sigma*sqrt(dt)*Z)\n",
    "        increments = 1 + mu * dt + sigma * torch.sqrt(torch.tensor(dt)) * Z\n",
    "        prices = S0 * torch.cumprod(increments, dim=0) #return values in proces and not in log-prices\n",
    "        return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f1224-c4b0-4e40-96c7-f4cd362760c6",
   "metadata": {},
   "source": [
    "To test the above method, its compliance to this maybe checked: $E[S_T] = S_0 e^{\\mu T}$\n",
    "\n",
    "this results from the analytical solution to the GBM SDE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468d98bd-e795-48a0-a151-2853fd235f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Std. Error of the Mean is 0.06745587289333344\n"
     ]
    }
   ],
   "source": [
    "# Test for the above method\n",
    "# To check the compliance of the method with the Expected value, the mean across a large sample is tested\n",
    "\n",
    "def test_gbm_mean_pytorch():\n",
    "    S0, mu, sigma, T, dt = 100.0, 0.05, 0.2, 1.0, 0.001\n",
    "    n_paths = 100000\n",
    "\n",
    "    # generate price-paths\n",
    "    prices = pyt_gbm(S0, mu, sigma, T, dt, n_paths)\n",
    "    terminal_prices = prices[-1] # consider only the final prices\n",
    "    \n",
    "    theoretical_mean = S0 * torch.exp(torch.tensor(mu * T)) # value for generated data to be checked against \n",
    "    theoretical_mean = theoretical_mean.cpu()\n",
    "    sample_mean = terminal_prices.mean().item() \n",
    "    \n",
    "    # standard error of the mean = sigma_sample / sqrt(n)\n",
    "    sem = terminal_prices.std().item() / torch.sqrt(torch.tensor(n_paths))\n",
    "\n",
    "    # log findings \n",
    "    print(f'The Std. Error of the Mean is {sem}')\n",
    "\n",
    "    # assert within 3 standard errors (99.7% confidence)\n",
    "    assert abs(sample_mean - theoretical_mean) < 3 * sem\n",
    "\n",
    "# Perform the test\n",
    "test_gbm_mean_pytorch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1823c-5e28-4123-ac82-c74a79204b9d",
   "metadata": {},
   "source": [
    "### Heston Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3bc63-1c23-473d-8ed9-489195eb5fb3",
   "metadata": {},
   "source": [
    "The Heston models differs primarily from the GBM in that it models volatility as a non-constant stochastic process.\n",
    "This increases the realism of the simulation by being able to capture market dynamics such as spikes in volatility when there are price drops etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7b5ac-d17c-4f62-b2b8-6b665869b064",
   "metadata": {},
   "source": [
    "The model:\n",
    "       $$ dS_t = \\mu  S_t  dt + \\sqrt(v_t) S_t  dW1_t $$\n",
    "       $$  dv_t = \\kappa  (\\theta - v_t)  dt + \\sigma_v  \\sqrt(v_t)  dW2_t $$ \n",
    "        \n",
    "where:\n",
    "       $$ S_t - \\text{is the  stock price} $$\n",
    "       $$ v_t -  \\text{variance} $$\n",
    "       $$ dW1_t, dW2_t -  \\text{correlated Brownian motions with correlation rho} $$\n",
    "       $$ \\text{the two Brownian motions are linked by the correlation } \\rho \\text{ by } d\\langle W^S, W^v \\rangle_t = \\rho dt $$\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd6b40-2684-4707-be7c-65d6e53f8a2b",
   "metadata": {},
   "source": [
    "The Parameters in the equations above:\n",
    "* $\\mu$ : The expected return of the asset (often set to $r$, the risk-free rate which should hold as a risk-neutral measure).\n",
    "* $\\sqrt{v_t}$ (Stochastic Volatility): this is the volatility at any time-step or $d_t$, i.e., the instantaneous volatility.\n",
    "* $\\kappa$ (Mean Reversion Speed): the rate at which the volatility returns to the long-run average.\n",
    "* $\\theta$ (Long-Run Variance): The mean level that variance gravitates toward.\n",
    "* $\\xi$ (Vol of Vol): The volatility that the variance process follows.\n",
    "* $\\rho$ (Correlation): This is the correlation between the two Brownian motions for asset prices and asset variances.\n",
    "  $\\rho$ is usually negative to capture market dynamics of variance of asset prices rising as the asset prices fall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85b183f-a715-4194-a1f9-ad8d3b2c5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heston_simulation(\n",
    "        n_paths: int = 5,\n",
    "        S0: float = 100.0,          # starting stock price\n",
    "        v0: float = 0.04,           # starting variance (vol^2, so sqrt(0.04)=0.2 or 20% volatility)\n",
    "        mu: float = 0.05,           # drift of the process\n",
    "        kappa: float = 2.0,         # mean reversion speed\n",
    "        theta: float = 0.04,        # long-term variance\n",
    "        sigma_v: float = 0.3,       # volatility of volatility \n",
    "        rho: float = -0.7,          # correlation between asset price and variance\n",
    "        T: float = 1.0,             # overall time horizon\n",
    "        dt: float = 0.01,           # time step\n",
    "        scheme: str = 'euler',       # 'euler' first then 'milstein' or 'truncated' ##TODO: implement Milstein and Truncated methods\n",
    "        device = 'cpu'\n",
    "    ):\n",
    "    \"\"\"\n",
    "        Simulates Heston model given asset price paths\n",
    "        \n",
    "        Returns:\n",
    "            S - torch.Tensor of shape (n_paths, n_steps + 1) containing price paths\n",
    "            v - torch.Tensor of shape (n_paths, n_steps + 1) containing variance paths\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    \n",
    "    n_steps = int(T/dt) #torch.tensor(int (T / dt))\n",
    "    n_paths = int(n_paths) #n_paths = torch.tensor(n_paths)\n",
    "    rho = torch.tensor(rho)\n",
    "\n",
    "    #generate dW_S, dW_v\n",
    "    sqrt_dt = torch.sqrt(torch.tensor(dt))\n",
    "    # independent normal distributions as starting points\n",
    "    Z1 = torch.randn(n_paths, n_steps, device=device)\n",
    "    Z2 = torch.randn(n_paths, n_steps, device=device)\n",
    "    # induce the correlation rho in the Brownian motions\n",
    "    dW_S = sqrt_dt * Z1 # dW_S = sqrt(dt) * Z1\n",
    "    dW_v = sqrt_dt * (rho * Z1 + torch.sqrt(1 - rho**2) * Z2) # dW_v = sqrt(dt) * (rho * Z1 + sqrt(1 - rho^2) * Z2)\n",
    "\n",
    "    S = torch.zeros(n_paths, n_steps + 1, device=device)\n",
    "    v = torch.zeros(n_paths, n_steps + 1, device=device)\n",
    "    \n",
    "    S[:, 0] = S0 #set the first price to starting price\n",
    "    v[:, 0] = v0 #set the first variance to starting variance\n",
    "\n",
    "    #turn to torch for cuda usage\n",
    "    kappa = torch.tensor(kappa)\n",
    "    theta = torch.tensor(theta)\n",
    "    sigma_v = torch.tensor(sigma_v)\n",
    "    mu = torch.tensor(mu)\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        v_pos = torch.clamp(v[:, t], min=0.0) #keep variance positive, since the next column is being updated per loop\n",
    "        sqrt_v = torch.sqrt(v_pos)\n",
    "        # update variance as per the Heston equation dv = kappa*(theta - v)*dt + sigma_v*sqrt(v)*dW_v\n",
    "        v[:, t+1] = v[:, t] + kappa * (theta - v_pos) * dt + sigma_v * sqrt_v * dW_v[:, t]\n",
    "        # update stock price as per Heston equation dS = mu*S*dt + sqrt(v)*S*dW_S  <-- \n",
    "        S[:, t+1] = S[:, t] * (1 + mu * dt + sqrt_v * dW_S[:, t])\n",
    "    \n",
    "    return S, v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bd5f18-cb9a-4900-b91a-5351fdce449f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 101]), torch.Size([5, 101]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S, v = heston_simulation()\n",
    "S.shape, v.shape\n",
    "#S, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0c9d48-d59c-452a-9874-52f8c17e7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit simulation into a simple NN\n",
    "from torch.nn import Module\n",
    "\n",
    "\n",
    "class DeepHedgingMLPHeston(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int = 4, # [S_t -> asset price, v_t -> asset variance, delta_{t-1} -> asset volume held, pi_{t-1} -> PnL]\n",
    "                 hidden_dims: list = [64, 64], #hidden layers of the NN\n",
    "                 output_dim: int = 1): #output -> hedging decision\n",
    "        super().__init__()\n",
    "        layers = [] #to hold hidden dims and feed into nn.Sequential\n",
    "        prev_dim = input_dim\n",
    "        # pack in layers starting from input_dim through to the end of hidden dims, with a relu\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim)) #pack in output layer\n",
    "        self.network = nn.Sequential(*layers) #pack in the hidden layers\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x)\n",
    "\n",
    "class EuropeanCallPayoff:\n",
    "    def __init__(self, strike: float = 100.0):\n",
    "        self.strike = strike\n",
    "        \n",
    "    def __call__(self, S_T: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Args: S_T: Terminal stock prices, shape (n_paths,)\n",
    "        Returns: Payoffs, shape (n_paths,)\n",
    "        '''\n",
    "        return torch.relu(S_T - self.strike) # max(S-K, 0)\n",
    "\n",
    "def simple_euro_payoff(S_T: torch.Tensor, strike: float):\n",
    "    return torch.relu(S_T - strike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7203d8de-1a78-4f1c-a372-57c56e8d2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class DeepHedgingAgentHeston:\n",
    "    def __init__(self, model: nn.Module, transaction_cost: float = 0.001):\n",
    "        self.model = model\n",
    "        self.tc = transaction_cost\n",
    "        \n",
    "    def hedge_path(\n",
    "        self, \n",
    "        S_path: torch.Tensor, # asset price path from Heston model\n",
    "        v_path: torch.Tensor, # asset variance \"path\" from Heston model\n",
    "        payoff: torch.Tensor  # final PnL amount\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        execute hedging strategy on the given price and variance paths\n",
    "        \n",
    "        Args:\n",
    "            S_path: Price path with shape (batch_size, n_steps + 1)\n",
    "            v_path: Variance path with shape (batch_size, n_steps + 1)\n",
    "            payoff: Terminal payoff with shape (batch_size,)\n",
    "            \n",
    "        Returns:\n",
    "            final_pnl: Final PnL of shape (batch_size,)\n",
    "            hedge_positions: Hedging positions over time\n",
    "        '''\n",
    "        batch_size, n_steps_plus_1 = S_path.shape\n",
    "        n_steps = n_steps_plus_1 - 1\n",
    "        device = S_path.device # decide cuda if from cuda\n",
    "        \n",
    "        delta = torch.zeros(batch_size, 1, device=device)\n",
    "        pnl = torch.zeros(batch_size, device=device)\n",
    "        hedge_positions = torch.zeros(batch_size, n_steps, device=device)\n",
    "        \n",
    "        for t in range(n_steps):\n",
    "            S_t = S_path[:, t].unsqueeze(1)\n",
    "            v_t = v_path[:, t].unsqueeze(1)  \n",
    "            \n",
    "            # network input: [S_t, v_t, delta_{t-1}, pnl_{t-1}]\n",
    "            net_input = torch.cat([S_t, v_t, delta, pnl.unsqueeze(1)], dim=1)\n",
    "            \n",
    "            delta_new = self.model(net_input)\n",
    "            trade = delta_new - delta\n",
    "            tc_cost = self.tc * torch.abs(trade * S_t).squeeze()\n",
    "            \n",
    "            if t > 0:\n",
    "                price_change = S_path[:, t] - S_path[:, t-1]\n",
    "                pnl += delta.squeeze() * price_change\n",
    "            \n",
    "            pnl -= tc_cost\n",
    "            delta = delta_new\n",
    "            hedge_positions[:, t] = delta.squeeze()\n",
    "        \n",
    "        # final PnL\n",
    "        final_price_change = S_path[:, -1] - S_path[:, -2]\n",
    "        pnl += delta.squeeze() * final_price_change\n",
    "        pnl -= payoff\n",
    "        \n",
    "        return pnl, hedge_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3819042-97d4-44a9-83fd-11627605aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class DeepHedgingAgentHeston:\n",
    "    def __init__(self, model: nn.Module, transaction_cost: float = 0.001):\n",
    "        self.model = model\n",
    "        self.tc = transaction_cost\n",
    "        \n",
    "    def hedge_path(\n",
    "        self, \n",
    "        S_path: torch.Tensor, # asset price path from Heston model\n",
    "        v_path: torch.Tensor, # asset variance \"path\" from Heston model\n",
    "        payoff: torch.Tensor  # final PnL amount\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        execute hedging strategy on the given price and variance paths\n",
    "        \n",
    "        Args:\n",
    "            S_path: Price path with shape (batch_size, n_steps + 1)\n",
    "            v_path: Variance path with shape (batch_size, n_steps + 1)\n",
    "            payoff: Terminal payoff with shape (batch_size,)\n",
    "            \n",
    "        Returns:\n",
    "            final_pnl: Final PnL of shape (batch_size,)\n",
    "            hedge_positions: Hedging positions over time\n",
    "        '''\n",
    "        batch_size, n_steps_plus_1 = S_path.shape\n",
    "        n_steps = n_steps_plus_1 - 1\n",
    "        device = S_path.device # decide cuda if from cuda\n",
    "        \n",
    "        delta = torch.zeros(batch_size, 1, device=device)\n",
    "        pnl = torch.zeros(batch_size, device=device)\n",
    "        hedge_positions = torch.zeros(batch_size, n_steps, device=device)\n",
    "        \n",
    "        for t in range(n_steps):\n",
    "            S_t = S_path[:, t].unsqueeze(1)\n",
    "            v_t = v_path[:, t].unsqueeze(1)  \n",
    "            \n",
    "            # network input: [S_t, v_t, delta_{t-1}, pnl_{t-1}]\n",
    "            net_input = torch.cat([S_t, v_t, delta, pnl.unsqueeze(1)], dim=1)\n",
    "            \n",
    "            delta_new = self.model(net_input)\n",
    "            trade = delta_new - delta\n",
    "            tc_cost = self.tc * torch.abs(trade * S_t).squeeze()\n",
    "            \n",
    "            if t > 0:\n",
    "                price_change = S_path[:, t] - S_path[:, t-1]\n",
    "                pnl += delta.squeeze() * price_change\n",
    "            \n",
    "            pnl -= tc_cost\n",
    "            delta = delta_new\n",
    "            hedge_positions[:, t] = delta.squeeze()\n",
    "        \n",
    "        # final PnL\n",
    "        final_price_change = S_path[:, -1] - S_path[:, -2]\n",
    "        pnl += delta.squeeze() * final_price_change\n",
    "        pnl -= payoff\n",
    "        \n",
    "        return pnl, hedge_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575c4043-1d9a-4b51-9718-73a09ae4ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CVar loss function\n",
    "def cvar_loss(pnl: torch.Tensor, alpha: float = 0.1) -> torch.Tensor:\n",
    "    '''\n",
    "    computes Conditional Value At Risk (CVar) as a loss function\n",
    "    CVar gives losses accrued at worst x% of the tail. \n",
    "\n",
    "    inputs:\n",
    "    pnl: tensor holding the current PnL\n",
    "    alpha: the x% over which to compute\n",
    "\n",
    "    return average value of alpha% of pnl samples with lowest values\n",
    "    '''\n",
    "    import torch\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    batch_size = pnl[0] # first value in tensor \n",
    "    num_rows_worst = max(1, int(alpha * batch_size))\n",
    "    sorted_pnl_rows, _ = torch.sort(pnl)\n",
    "    return sorted_pnl_rows[:num_rows_worst].mean() #return avg of alpha% worst values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24dc2773-8393-409e-bdce-41c8f6f7e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def train_deep_hedging_heston__(\n",
    "    model: nn.Module,\n",
    "    payoff_fn: Callable = EuropeanCallPayoff(),\n",
    "    n_epochs: int = 100,\n",
    "    n_paths_per_epoch: int = 1024,\n",
    "    batch_size: int = 256,\n",
    "    lr: float = 0.001,\n",
    "    transaction_cost: float = 0.001,\n",
    "    alpha: float = 0.05,\n",
    "    device: str = 'cpu'\n",
    "):\n",
    "    \"\"\"Train Deep Hedging model for Heston\"\"\"\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    agent = DeepHedgingAgentHeston(model, transaction_cost)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    \n",
    "    for epoch in range(1): #n_epochs\n",
    "        epoch_losses = []\n",
    "        n_batches = n_paths_per_epoch // batch_size\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            # simulate price and variance paths\n",
    "            S_paths, v_paths = heston_simulation(n_paths = batch_size, device = device) \n",
    "            payoffs = payoff_fn(S_paths[:, -1])\n",
    "            print(f'For batch_idx-{batch_idx}, payoffs.shape is {payoffs.shape}\\n \\\n",
    "            S_paths[:3, :3] is {S_paths[:3, :3] } and v_paths[:3, :3] is { v_paths[:3, :3]}, and \\\n",
    "            payoffs[:3] is {payoffs[:3]}')\n",
    "            #print(payoffs.shape)\n",
    "            \n",
    "            # execute hedging strategy\n",
    "            pnl, _ = agent.hedge_path(S_paths, v_paths, payoffs)\n",
    "            \n",
    "            # compute CVaR loss\n",
    "            loss = cvar_loss(pnl, alpha)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "        \n",
    "        avg_loss = torch.mean(torch.tensor(epoch_losses))\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'At Epoch No. {epoch+1}/{n_epochs}, CVaR Loss is {avg_loss:.4f}')\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5668c6-e550-4e35-b797-b4b0311eed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch_idx-0, payoffs.shape is torch.Size([256])\n",
      "             S_paths[:3, :3] is tensor([[100.0000,  96.2059,  92.3677],\n",
      "        [100.0000, 100.1506,  99.5477],\n",
      "        [100.0000, 101.5181, 101.3800]], device='cuda:0') and v_paths[:3, :3] is tensor([[0.0400, 0.0526, 0.0600],\n",
      "        [0.0400, 0.0353, 0.0397],\n",
      "        [0.0400, 0.0374, 0.0362]], device='cuda:0'), and             payoffs[:3] is tensor([ 0.0000, 10.6997,  0.0000], device='cuda:0')\n",
      "For batch_idx-1, payoffs.shape is torch.Size([256])\n",
      "             S_paths[:3, :3] is tensor([[100.0000, 102.2138, 101.5347],\n",
      "        [100.0000, 103.3844, 105.7877],\n",
      "        [100.0000, 100.7267,  99.7834]], device='cuda:0') and v_paths[:3, :3] is tensor([[0.0400, 0.0262, 0.0270],\n",
      "        [0.0400, 0.0312, 0.0307],\n",
      "        [0.0400, 0.0387, 0.0348]], device='cuda:0'), and             payoffs[:3] is tensor([ 7.5789,  1.9780, 13.8036], device='cuda:0')\n",
      "For batch_idx-2, payoffs.shape is torch.Size([256])\n",
      "             S_paths[:3, :3] is tensor([[100.0000,  96.2927,  91.8140],\n",
      "        [100.0000, 102.8824, 100.9464],\n",
      "        [100.0000, 103.3990, 106.1054]], device='cuda:0') and v_paths[:3, :3] is tensor([[0.0400, 0.0469, 0.0575],\n",
      "        [0.0400, 0.0368, 0.0436],\n",
      "        [0.0400, 0.0311, 0.0211]], device='cuda:0'), and             payoffs[:3] is tensor([ 6.2719, 10.1733, 28.8654], device='cuda:0')\n",
      "For batch_idx-3, payoffs.shape is torch.Size([256])\n",
      "             S_paths[:3, :3] is tensor([[100.0000,  97.5188,  97.3540],\n",
      "        [100.0000, 100.6847,  98.4517],\n",
      "        [100.0000, 101.7183, 102.6505]], device='cuda:0') and v_paths[:3, :3] is tensor([[0.0400, 0.0390, 0.0371],\n",
      "        [0.0400, 0.0386, 0.0498],\n",
      "        [0.0400, 0.0309, 0.0277]], device='cuda:0'), and             payoffs[:3] is tensor([24.0198,  0.0000,  0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model, losses =  train_deep_hedging_heston__(DeepHedgingMLPHeston())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec45c7b-54c2-43a5-996e-0d4371915cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def train_deep_hedging_heston(\n",
    "    model: nn.Module,\n",
    "    payoff_fn: Callable = EuropeanCallPayoff(),\n",
    "    n_epochs: int = 100,\n",
    "    n_paths_per_epoch: int = 1024,\n",
    "    batch_size: int = 256,\n",
    "    lr: float = 0.001,\n",
    "    transaction_cost: float = 0.001,\n",
    "    alpha: float = 0.05,\n",
    "    device: str = 'cpu'\n",
    "):\n",
    "    \"\"\"Train Deep Hedging model for Heston\"\"\"\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    agent = DeepHedgingAgentHeston(model, transaction_cost)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        n_batches = n_paths_per_epoch // batch_size\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            # simulate price and variance paths\n",
    "            S_paths, v_paths = heston_simulation(n_paths = batch_size, device = device) \n",
    "            payoffs = payoff_fn(S_paths[:, -1])\n",
    "            #print(payoffs.shape)\n",
    "            \n",
    "            # execute hedging strategy\n",
    "            pnl, _ = agent.hedge_path(S_paths, v_paths, payoffs)\n",
    "            \n",
    "            # compute CVaR loss\n",
    "            loss = cvar_loss(pnl, alpha)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "        \n",
    "        avg_loss = torch.mean(torch.tensor(epoch_losses))\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'At Epoch No. {epoch+1}/{n_epochs}, CVaR Loss is {avg_loss:.4f}')\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ae25ca2-62b2-47a7-8f71-75d3f1a8adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch No. 10/100, CVaR Loss is -1131528585216.0000\n",
      "At Epoch No. 20/100, CVaR Loss is -93539482785508491264.0000\n",
      "At Epoch No. 30/100, CVaR Loss is -3744417705085489905664.0000\n",
      "At Epoch No. 40/100, CVaR Loss is -221937723888352886784.0000\n",
      "At Epoch No. 50/100, CVaR Loss is -2301204444534013952.0000\n",
      "At Epoch No. 60/100, CVaR Loss is -120961812955637219328.0000\n",
      "At Epoch No. 70/100, CVaR Loss is -336770489594859749376.0000\n",
      "At Epoch No. 80/100, CVaR Loss is -9854394954174955520.0000\n",
      "At Epoch No. 90/100, CVaR Loss is -215157906493067493376.0000\n",
      "At Epoch No. 100/100, CVaR Loss is -9768062400673611776.0000\n"
     ]
    }
   ],
   "source": [
    "cvar_trained_model, losses = train_deep_hedging_heston(DeepHedgingMLPHeston())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a35fa3b6-e6d2-4989-b2b5-1da8b584d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropic loss function\n",
    "def entropic_risk_loss(pnl: torch.Tensor, beta: float = 0.1) -> torch.Tensor:\n",
    "    '''\n",
    "    computes entropic loss as a loss function\n",
    "    entropic loss := (1/beta) * log(E[exp(-beta * PnL)])\n",
    "\n",
    "    inputs:\n",
    "    pnl: tensor holding the current PnL\n",
    "    beta: risk sensitivity parameter, it penalizes losses in PnL, the higher the beta more severly will PnL losses be penalized\n",
    "\n",
    "    return aentropic loss as scalar tensor\n",
    "    '''\n",
    "    import torch\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    return (1.0 / beta) * torch.log(torch.exp(-beta * pnl).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0d66e48-a2a2-4445-833b-951c6957edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def train_deep_hedging_heston_entropic(\n",
    "    model: nn.Module,\n",
    "    payoff_fn: Callable = EuropeanCallPayoff(),\n",
    "    n_epochs: int = 100,\n",
    "    n_paths_per_epoch: int = 1024,\n",
    "    batch_size: int = 256,\n",
    "    lr: float = 0.001,\n",
    "    transaction_cost: float = 0.001,\n",
    "    alpha: float = 0.05,\n",
    "    device: str = 'cpu'\n",
    "):\n",
    "    \"\"\"Train Deep Hedging model for Heston\"\"\"\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    agent = DeepHedgingAgentHeston(model, transaction_cost)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        n_batches = n_paths_per_epoch // batch_size\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            # simulate price and variance paths\n",
    "            S_paths, v_paths = heston_simulation(n_paths = batch_size, device = device) #simulator.simulate_with_variance(batch_size, device=device)\n",
    "            payoffs = payoff_fn(S_paths[:, -1])\n",
    "            #print(payoffs.shape)\n",
    "            \n",
    "            # execute hedging strategy\n",
    "            pnl, _ = agent.hedge_path(S_paths, v_paths, payoffs)\n",
    "            \n",
    "            # compute entropic loss\n",
    "            loss = entropic_risk_loss(pnl, alpha)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "        \n",
    "        avg_loss = torch.mean(torch.tensor(epoch_losses))\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'At Epoch No. {epoch+1}/{n_epochs}, Entropic Loss is {avg_loss:.4f}')\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9847b82-f883-45dd-832a-575b62ea4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch No. 10/100, Entropic Loss is 8.0561\n",
      "At Epoch No. 20/100, Entropic Loss is 8.0629\n",
      "At Epoch No. 30/100, Entropic Loss is 7.8561\n",
      "At Epoch No. 40/100, Entropic Loss is 8.0338\n",
      "At Epoch No. 50/100, Entropic Loss is 8.0583\n",
      "At Epoch No. 60/100, Entropic Loss is 7.8276\n",
      "At Epoch No. 70/100, Entropic Loss is 7.5737\n",
      "At Epoch No. 80/100, Entropic Loss is 7.6689\n",
      "At Epoch No. 90/100, Entropic Loss is 8.1905\n",
      "At Epoch No. 100/100, Entropic Loss is 7.7507\n"
     ]
    }
   ],
   "source": [
    "entropic_trained_model, losses = train_deep_hedging_heston_entropic(DeepHedgingMLPHeston())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f509b9e8-97a3-4790-910f-d3959eab300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple performance check\n",
    "import yfinance as yf\n",
    "import pandas\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80c7278e-552f-45ee-a004-4ae183203d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL data for testing...\n",
      "Downloaded data for asset AAPL of 1006 days of data.\n",
      "Starting date 2020-01-01 and ending date 2023-12-31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_market_data(ticker='AAPL', start='2020-01-01', end='2023-12-31'):\n",
    "    '''Get historical stock data to run model on actual data not simulated ones.'''\n",
    "    print(f'Downloading {ticker} data for testing...')\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(start=start, end=end)\n",
    "    print(f'Downloaded data for asset {ticker} of {len(data)} days of data.\\nStarting date {start} and ending date {end}\\n')\n",
    "    return data\n",
    "historical_data = load_market_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77e1a05c-fea4-4984-9e99-98666359175c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     17\u001b[39m     realized_var = returns.rolling(window=window).var() * \u001b[32m252\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame({\n\u001b[32m     20\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m: prices,\n\u001b[32m     21\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mReturns\u001b[39m\u001b[33m'\u001b[39m: returns,\n\u001b[32m     22\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mVariance\u001b[39m\u001b[33m'\u001b[39m: realized_var\n\u001b[32m     23\u001b[39m     }).dropna()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m market_df = \u001b[43mcompute_realized_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistorical_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m21\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessed data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(market_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m days\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAverage realized volatility: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.sqrt(market_df[\u001b[33m'\u001b[39m\u001b[33mVariance\u001b[39m\u001b[33m'\u001b[39m].mean())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcompute_realized_variance\u001b[39m\u001b[34m(data, window)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     11\u001b[39m device = \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m prices = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mClose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m prices_rolled = torch.roll(prices, shifts=\u001b[32m1\u001b[39m, dims=\u001b[32m0\u001b[39m) \n\u001b[32m     14\u001b[39m returns = torch.log(prices / prices.shift(\u001b[32m1\u001b[39m))\n",
      "\u001b[31mValueError\u001b[39m: could not determine the shape of object type 'Series'"
     ]
    }
   ],
   "source": [
    "def compute_realized_variance(data, window=21):\n",
    "    '''\n",
    "    Estimate variance from historical data\n",
    "    Args:\n",
    "        data: DataFrame of actual stock -- with 'Close' prices\n",
    "        window: Rolling window for variance calculation, default value of 21 to approximate trading days in a month\n",
    "    '''\n",
    "    import torch\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    prices = torch.tensor(data['Close'], device=device)\n",
    "    prices_rolled = torch.roll(prices, shifts=1, dims=0) \n",
    "    returns = torch.log(prices / prices.shift(1))\n",
    "    \n",
    "    # Realized variance - annualized\n",
    "    realized_var = returns.rolling(window=window).var() * 252\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Price': prices,\n",
    "        'Returns': returns,\n",
    "        'Variance': realized_var\n",
    "    }).dropna()\n",
    "\n",
    "market_df = compute_realized_variance(historical_data, window=21)\n",
    "print(f'\\nProcessed data: {len(market_df)} days')\n",
    "print(f'Average realized volatility: {np.sqrt(market_df['Variance'].mean()):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14407cd1-5829-4b42-9e46-2b0ad95161d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ced2c-f642-43c7-8b7e-8ab1ec8f5d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9fa58f-47cb-46a0-a535-4f2b3a04b752",
   "metadata": {},
   "source": [
    "Attic Below: Delete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ffba099-83ee-42c1-83fd-b72fd1a50a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "def evaluate_hedging_heston(\n",
    "    model: nn.Module,\n",
    "    simulator: Callable,\n",
    "    payoff_fn: Callable,\n",
    "    n_paths: int = 10000,\n",
    "    transaction_cost: float = 0.001,\n",
    "    device: str = 'cpu'\n",
    "):\n",
    "    \n",
    "    model.eval()\n",
    "    agent = DeepHedgingAgentHeston(model, transaction_cost)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        S_paths, v_paths = simulator(n_paths, device=device)\n",
    "        payoffs = payoff_fn(S_paths[:, -1])\n",
    "        pnl, hedge_positions = agent.hedge_path(S_paths, v_paths, payoffs)\n",
    "        \n",
    "        pnl_np = pnl.cpu().numpy()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"HESTON MODEL EVALUATION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Mean P&L: ${pnl_np.mean():.4f}\")\n",
    "        print(f\"Std P&L: ${pnl_np.std():.4f}\")\n",
    "        print(f\"Min P&L: ${pnl_np.min():.4f}\")\n",
    "        print(f\"Max P&L: ${pnl_np.max():.4f}\")\n",
    "        print(f\"VaR(5%): ${np.percentile(pnl_np, 5):.4f}\")\n",
    "        print(f\"CVaR(5%): ${pnl_np[pnl_np <= np.percentile(pnl_np, 5)].mean():.4f}\")\n",
    "        \n",
    "        return pnl_np, hedge_positions.cpu().numpy(), S_paths.cpu().numpy(), v_paths.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed8e01-3621-4cfe-adbd-307df3f56b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1387e-7b5f-45e7-b9b8-38280e719b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0fd36-b5ac-4778-a3ce-67241a225083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a496b2b9-c47f-4eac-b170-0d1d0783e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GBMSimulator(MarketSimulator):\n",
    "    \"\"\"\n",
    "    Simulates markets assuming Constant Volatility.\n",
    "    \n",
    "    Equation: dS_t = mu * S_t * dt + sigma * S_t * dW_t\n",
    "    \"\"\"\n",
    "    def __init__(self, mu, sigma, dt, device='cpu'):\n",
    "        super().__init__(dt, device)\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def simulate(self, num_paths, num_steps, s0):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8356ef8-1e37-4f5d-85a3-a98d3ea5046b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707ac696-3fb9-4ba7-b94c-3154a70fe38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HestonSimulator(MarketSimulator):\n",
    "    \"\"\"\n",
    "    Simulates markets assuming Stochastic Volatility.\n",
    "    \n",
    "    Equation 1 (Price):    dS_t = mu * S_t * dt + sqrt(v_t) * S_t * dW_S\n",
    "    Equation 2 (Variance): dv_t = kappa * (theta - v_t) * dt + xi * sqrt(v_t) * dW_v\n",
    "    \"\"\"\n",
    "    def __init__(self, mu, kappa, theta, xi, rho, dt, device='cpu'):\n",
    "        super().__init__(dt, device)\n",
    "        self.mu = mu\n",
    "        self.kappa = kappa  # Mean reversion speed\n",
    "        self.theta = theta  # Long-run variance\n",
    "        self.xi = xi        # Vol of Vol\n",
    "        self.rho = rho      # Correlation (Leverage Effect)\n",
    "\n",
    "    def simulate(self, num_paths, num_steps, s0, v0):\n",
    "        # todo: Implementation of Euler-Maruyama with Full Truncation -- PyTorch\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6f9b4-773e-4ca4-bf14-c5f4d2b9550e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
